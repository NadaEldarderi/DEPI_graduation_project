{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6415bc",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de8d0346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU transformers==4.48.3 datasets==2.18.0 optimum==1.24.0\n",
    "# !pip install -qU json-repair==0.29.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91a0f04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers accelerate peft bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aac7f760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d1cba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --force-reinstall \"https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_multi-backend-refactor/bitsandbytes-0.44.1.dev0-py3-none-win_amd64.whl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe9c6e7",
   "metadata": {},
   "source": [
    "# Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dbfbbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d3162f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1889fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43694508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_model import getDetailExtractionMessage, getTranslationMessage\n",
    "from functions import parse_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c95a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693704b9",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d90d26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL_ID = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "TORCH_TYPE = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d79e519",
   "metadata": {},
   "source": [
    "# Model (Base Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d756ec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_ID,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype = TORCH_TYPE,\n",
    "    offload_folder=\"./offload_dir\"\n",
    ")\n",
    "\n",
    "tokenizer_temp = AutoTokenizer.from_pretrained(BASE_MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91f9e46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 1536)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19463cb7",
   "metadata": {},
   "source": [
    "# Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "758d5967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(message: str):\n",
    "    text = tokenizer_temp.apply_chat_template(\n",
    "        message,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    model_inputs = tokenizer_temp([text], return_tensors=\"pt\").to(base_model.device)\n",
    "\n",
    "    generated_ids = base_model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=False, top_k=None, temperature=None, top_p=None,\n",
    "    )\n",
    "\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):]\n",
    "        for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    response = tokenizer_temp.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a55a3280",
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"\"\"\n",
    "أنهى مسئولو النادى الأهلى كل تفاصيل عقد أحمد مصطفى زيزو، جناح الزمالك، بحيث ينضم اللاعب لمدة 4 سنوات قادمة بدءا من الموسم الجديد، فى صفقة انتقال حر بعد نهاية عقده مع الزمالك عقب نهاية الموسم الحالى.\n",
    "\n",
    "ووضع الأهلى زيزو فى الفئة الأولى بحيث يحصل على 25 مليون جنيه سنويا بالإضافة إلى عقد إعلانى مقابل 60 مليون جنيه، بخلاف 80 مليون جنيه أخرى سيحصل عليها دفعة واحدة من خارج النادى عند الإعلان الرسمى عن الصفقة.\n",
    "\n",
    "وينتهى عقد أحمد سيد زيزو مع الزمالك بنهاية الموسم الجارى، مما يجعل له الحق فى التفاوض مع أى نادٍ وإتمام الاتفاق معه والانضمام له عقب نهاية عقده الحالي خلال يونيو المقبل.\n",
    "\n",
    "وحصل زيزو على تأشيرة السفر لأمريكا بالفعل للمشاركة مع الأهلى في مونديال الأندية الصيف المقبل.\n",
    "\n",
    "ويستعد الأهلى للمشاركة فى بطولة كأس العالم للأندية بشكلها الجديد فى الولايات المتحدة الأمريكية، والمقامة بمشاركة 32 ناديًا من أكبر فرق العالم\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee47240",
   "metadata": {},
   "source": [
    "Before Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f592d0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an NLP data paraser.\\nYou will be provided by an Arabic text associated with a Pydantic scheme.\\nGenerate the ouptut in the same story language.\\nYou have to extract JSON details from text according the Pydantic details.\\nExtract details as mentioned in text.\\nDo not generate any introduction or conclusion.'},\n",
       " {'role': 'user',\n",
       "  'content': '## Story:\\nأنهى مسئولو النادى الأهلى كل تفاصيل عقد أحمد مصطفى زيزو، جناح الزمالك، بحيث ينضم اللاعب لمدة 4 سنوات قادمة بدءا من الموسم الجديد، فى صفقة انتقال حر بعد نهاية عقده مع الزمالك عقب نهاية الموسم الحالى.\\n\\nووضع الأهلى زيزو فى الفئة الأولى بحيث يحصل على 25 مليون جنيه سنويا بالإضافة إلى عقد إعلانى مقابل 60 مليون جنيه، بخلاف 80 مليون جنيه أخرى سيحصل عليها دفعة واحدة من خارج النادى عند الإعلان الرسمى عن الصفقة.\\n\\nوينتهى عقد أحمد سيد زيزو مع الزمالك بنهاية الموسم الجارى، مما يجعل له الحق فى التفاوض مع أى نادٍ وإتمام الاتفاق معه والانضمام له عقب نهاية عقده الحالي خلال يونيو المقبل.\\n\\nوحصل زيزو على تأشيرة السفر لأمريكا بالفعل للمشاركة مع الأهلى في مونديال الأندية الصيف المقبل.\\n\\nويستعد الأهلى للمشاركة فى بطولة كأس العالم للأندية بشكلها الجديد فى الولايات المتحدة الأمريكية، والمقامة بمشاركة 32 ناديًا من أكبر\\xa0فرق\\xa0العالم\\n\\n## Pydantic Details:\\n{\"$defs\": {\"Entity\": {\"properties\": {\"entity_value\": {\"description\": \"The actual name or value of the entity.\", \"title\": \"Entity Value\", \"type\": \"string\"}, \"entity_type\": {\"description\": \"The type of recognized entity.\", \"enum\": [\"person-male\", \"person-female\", \"location\", \"organization\", \"event\", \"time\", \"quantity\", \"money\", \"product\", \"law\", \"disease\", \"artifact\", \"not_specified\"], \"title\": \"Entity Type\", \"type\": \"string\"}}, \"required\": [\"entity_value\", \"entity_type\"], \"title\": \"Entity\", \"type\": \"object\"}}, \"properties\": {\"story_title\": {\"description\": \"A fully informative and SEO optimized title of the story.\", \"maxLength\": 300, \"minLength\": 5, \"title\": \"Story Title\", \"type\": \"string\"}, \"story_keywords\": {\"description\": \"Relevant keywords associated with the story.\", \"items\": {\"type\": \"string\"}, \"minItems\": 1, \"title\": \"Story Keywords\", \"type\": \"array\"}, \"story_summary\": {\"description\": \"Summarized key points about the story (1-5 points).\", \"items\": {\"type\": \"string\"}, \"maxItems\": 5, \"minItems\": 1, \"title\": \"Story Summary\", \"type\": \"array\"}, \"story_category\": {\"description\": \"Category of the news story.\", \"enum\": [\"politics\", \"sports\", \"art\", \"technology\", \"economy\", \"health\", \"entertainment\", \"science\", \"not_specified\"], \"title\": \"Story Category\", \"type\": \"string\"}, \"story_entities\": {\"description\": \"List of identified entities in the story.\", \"items\": {\"$ref\": \"#/$defs/Entity\"}, \"maxItems\": 10, \"minItems\": 1, \"title\": \"Story Entities\", \"type\": \"array\"}}, \"required\": [\"story_title\", \"story_keywords\", \"story_summary\", \"story_category\", \"story_entities\"], \"title\": \"NewsDetails\", \"type\": \"object\"}\\n\\n## Story Details:\\n```json'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getDetailExtractionMessage(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f48fa242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict(getDetailExtractionMessage(story))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be44239c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are a professional translator.\\nYou will be provided by an Arabic text.\\nYou have to translate the text into the `Targeted Language`.\\nFollow the provided Scheme to generate a JSON\\nDo not generate any introduction or conclusion.'},\n",
       " {'role': 'user',\n",
       "  'content': '## Story:\\nأنهى مسئولو النادى الأهلى كل تفاصيل عقد أحمد مصطفى زيزو، جناح الزمالك، بحيث ينضم اللاعب لمدة 4 سنوات قادمة بدءا من الموسم الجديد، فى صفقة انتقال حر بعد نهاية عقده مع الزمالك عقب نهاية الموسم الحالى.\\n\\nووضع الأهلى زيزو فى الفئة الأولى بحيث يحصل على 25 مليون جنيه سنويا بالإضافة إلى عقد إعلانى مقابل 60 مليون جنيه، بخلاف 80 مليون جنيه أخرى سيحصل عليها دفعة واحدة من خارج النادى عند الإعلان الرسمى عن الصفقة.\\n\\nوينتهى عقد أحمد سيد زيزو مع الزمالك بنهاية الموسم الجارى، مما يجعل له الحق فى التفاوض مع أى نادٍ وإتمام الاتفاق معه والانضمام له عقب نهاية عقده الحالي خلال يونيو المقبل.\\n\\nوحصل زيزو على تأشيرة السفر لأمريكا بالفعل للمشاركة مع الأهلى في مونديال الأندية الصيف المقبل.\\n\\nويستعد الأهلى للمشاركة فى بطولة كأس العالم للأندية بشكلها الجديد فى الولايات المتحدة الأمريكية، والمقامة بمشاركة 32 ناديًا من أكبر\\xa0فرق\\xa0العالم\\n\\n## Pydantic Details:\\n{\"properties\": {\"translated_title\": {\"description\": \"Suggested translated title of the news story.\", \"maxLength\": 300, \"minLength\": 5, \"title\": \"Translated Title\", \"type\": \"string\"}, \"translated_content\": {\"description\": \"Translated content of the news story.\", \"minLength\": 5, \"title\": \"Translated Content\", \"type\": \"string\"}}, \"required\": [\"translated_title\", \"translated_content\"], \"title\": \"TranslatedStory\", \"type\": \"object\"}\\n\\n## Targeted Language:\\nEnglish\\n\\n## Translated Story:\\n```json'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getTranslationMessage(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65f8f116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\\n  \"translated_title\": \"Ahmed Moustafa Zizou\\'s Contract Ends with Cairo Eagles\",\\n  \"translated_content\": \"The management of Al Ahli has finalized all details regarding Ahmed Moustafa Zizou\\'s contract, which he will join for four years starting from next season. The deal is free transfer after his contract expires with Al Ahli at the end of this season.\"\\n}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict(getTranslationMessage(story))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a62b70",
   "metadata": {},
   "source": [
    "After Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8b55a05",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "We need an `offload_dir` to dispatch this model according to this `device_map`, the following submodules need to be offloaded: model.layers.6, model.layers.7, model.layers.8, model.layers.9, model.layers.10, model.layers.11, model.layers.12, model.layers.13, model.layers.14, model.layers.15, model.layers.16, model.layers.17, model.layers.18, model.layers.19, model.layers.20, model.layers.21, model.layers.22, model.layers.23, model.layers.24, model.layers.25, model.layers.26, model.layers.27, model.norm, model.rotary_emb.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m finetuned_model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinetuned_model_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yosef\\anaconda3\\envs\\my-env\\lib\\site-packages\\transformers\\integrations\\peft.py:276\u001b[0m, in \u001b[0;36mPeftAdapterMixin.load_adapter\u001b[1;34m(self, peft_model_id, adapter_name, revision, token, device_map, max_memory, offload_folder, offload_index, peft_config, adapter_state_dict, low_cpu_mem_usage, is_trainable, adapter_kwargs)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;66;03m# Re-dispatch model and hooks in case the model is offloaded to CPU / Disk.\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    272\u001b[0m     (\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf_device_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhf_device_map\u001b[38;5;241m.\u001b[39mvalues())\u001b[38;5;241m.\u001b[39mintersection({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m})) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeft_config) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    275\u001b[0m ):\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_accelerate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yosef\\anaconda3\\envs\\my-env\\lib\\site-packages\\transformers\\integrations\\peft.py:523\u001b[0m, in \u001b[0;36mPeftAdapterMixin._dispatch_accelerate_model\u001b[1;34m(self, device_map, max_memory, offload_folder, offload_index)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    520\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m infer_auto_device_map(\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;28mself\u001b[39m, max_memory\u001b[38;5;241m=\u001b[39mmax_memory, no_split_module_classes\u001b[38;5;241m=\u001b[39mno_split_module_classes\n\u001b[0;32m    522\u001b[0m     )\n\u001b[1;32m--> 523\u001b[0m dispatch_model(\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    525\u001b[0m     device_map\u001b[38;5;241m=\u001b[39mdevice_map,\n\u001b[0;32m    526\u001b[0m     offload_dir\u001b[38;5;241m=\u001b[39moffload_folder,\n\u001b[0;32m    527\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdispatch_model_kwargs,\n\u001b[0;32m    528\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\yosef\\anaconda3\\envs\\my-env\\lib\\site-packages\\accelerate\\big_modeling.py:380\u001b[0m, in \u001b[0;36mdispatch_model\u001b[1;34m(model, device_map, main_device, state_dict, offload_dir, offload_index, offload_buffers, skip_keys, preload_module_classes, force_hooks)\u001b[0m\n\u001b[0;32m    378\u001b[0m disk_modules \u001b[38;5;241m=\u001b[39m [name \u001b[38;5;28;01mfor\u001b[39;00m name, device \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m offload_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m offload_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(disk_modules) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 380\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    381\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe need an `offload_dir` to dispatch this model according to this `device_map`, the following submodules \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    382\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneed to be offloaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(disk_modules)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m     )\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mlen\u001b[39m(disk_modules) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m offload_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(offload_dir) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(offload_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[0;32m    388\u001b[0m ):\n\u001b[0;32m    389\u001b[0m     disk_state_dict \u001b[38;5;241m=\u001b[39m extract_submodules_state_dict(model\u001b[38;5;241m.\u001b[39mstate_dict(), disk_modules)\n",
      "\u001b[1;31mValueError\u001b[0m: We need an `offload_dir` to dispatch this model according to this `device_map`, the following submodules need to be offloaded: model.layers.6, model.layers.7, model.layers.8, model.layers.9, model.layers.10, model.layers.11, model.layers.12, model.layers.13, model.layers.14, model.layers.15, model.layers.16, model.layers.17, model.layers.18, model.layers.19, model.layers.20, model.layers.21, model.layers.22, model.layers.23, model.layers.24, model.layers.25, model.layers.26, model.layers.27, model.norm, model.rotary_emb."
     ]
    }
   ],
   "source": [
    "finetuned_model_id = \"models\"\n",
    "base_model.load_adapter(finetuned_model_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
